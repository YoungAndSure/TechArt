{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff8f6c39",
   "metadata": {},
   "source": [
    "什么是funtional/泛函数？  \n",
    "这会儿简单理解，就是函数的函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858688f3",
   "metadata": {},
   "source": [
    "supervised learning包含classification problem和regression problem.监督学习是说样本里有输入向量和对应的目标向量。分类问题输出是离散变量，回归输出是连续变量。  \n",
    "回归一次的来源是研究两代人身高，发现下一代会趋于平均值，这个趋于平均值叫回归regression。没想清楚怎么跟这里的回归对应上的。  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c841dbb",
   "metadata": {},
   "source": [
    "只有输入向量，没有目标向量的是unsupervised learning。包含clustering和density estimation。聚类是把点分类，回答这个点属于哪个分类的问题。密度估计是得出点的分布。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571b441d",
   "metadata": {},
   "source": [
    "很高兴又看到credit assignment problem,之前读mfrl时候只get到了explorition和exploitation问题，没有意识到信用分配的问题。信用分配说的是，如何把reward合理分配到action的问题。一个回合结束后得到轨迹的return，这个回合中那么多action，哪个对这个return贡献多？哪个对这个return贡献少？需要有个分配，credit assignment problem讨论的就是如何分配的问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8155acf-c320-4be4-91c9-8b52025aae02",
   "metadata": {},
   "source": [
    "有意思，为什么多项式里的$x$明明是$M$阶的，这种模型还叫linear model?因为从参数$w$的角度看，是线性的，本来要调整的也是$w$，所以这个叫linear model。  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c565a0-0f04-43da-ae25-9524c76ad6a4",
   "metadata": {},
   "source": [
    "Figure1.4: 多项式阶数过高，就是过拟合，泛化能力一定下降。拟合能力和泛化能力就是互斥的一对，有你没我有我没你。  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d66cb9-2d9c-45f7-a4f7-7e6d60633f47",
   "metadata": {},
   "source": [
    "#### 均方误差(RMS)和平方误差和比，有什么区别？  \n",
    "平方误差和：  \n",
    "$E(\\mathbf{w}) = \\sum_{n=1}^N\\{y(x_n, \\mathbf{w}) - t_n\\}^2$  \n",
    "均方误差：  \n",
    "$E_{RMS}(\\mathbf{w}) = \\sqrt{2E(\\mathbf{w})/N}$  \n",
    "$N$可以消去数据集大小的影响，让不同数据集之间可比。  \n",
    "$\\sqrt{}$让误差落回和目标$t$一样的尺度，可以和$t$来比较看差异。  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfed900-3607-4ac4-bc87-9be5dca4541f",
   "metadata": {},
   "source": [
    "有道理啊，三阶多项式是九阶多项式在高阶系数等于=0时的特例，九阶多项式的表达能力应该强于三阶。况且，模拟数据通过$\\sin(2\\pi x)$生成，无穷阶的二项式可以逼近$\\sin(2\\pi x)$，所以阶数越多，越能逼近才对。为什么反倒九阶的拟合效果还不如三阶呢？  \n",
    "写到这我还没看下边的内容，盲猜一下为什么。  \n",
    "限制九阶泛化能力的是数据而不是九阶本身。如果数据足够多，九阶肯定比三阶好，无穷阶更好。数据给的信息不全，目标没有指向$\\sin(2\\pi x)$，所以九阶能力强但学的方向错了。  \n",
    "答对了。不过这也挺好理解，数据越多，噪声的影响就越少，就越能学到真实的分布。  \n",
    "  \n",
    "最终是说，数据量必须得是参数量的一个倍数时候，才不会过拟合。  \n",
    "然后作者装了个逼，说，最小二乘不过是最大似然的一个特例，过拟合是最大似然的普遍问题，而从贝叶斯的视角出发，贝叶斯模型不要求参数量和数据量的关系，会自动选择参数量。  \n",
    "听着就牛逼。  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9a9549-7510-419b-912c-83bd3e22d66b",
   "metadata": {},
   "source": [
    "Note that often the coefficient w0 is omitted from the regularizer because its\n",
    "inclusion causes the results to depend on the choice of origin for the target variable\n",
    "(Hastie et al., 2001), or it may be included but with its own regularization coefficient\n",
    "(we shall discuss this topic in more detail in Section 5.5.1).\n",
    "  \n",
    "英语角度，没意识到inclusion是个名词，是its inclusion，包含它，而不是个动词。  \n",
    "算法角度。  \n",
    "首先，什么是正则化？"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
