# 推荐系统中的一致性

## 前言
过去在新闻做的，都是精排、特征、离线样本流，没有接触策略逻辑。说起一致性，想到的都是离在线样本的一致性、在线各模块预估时样本的一致性。到了快手之后，接触到了策略，才理解到，还有一种一致性，是级联系统各模块间策略的一致性。一日午休后散步间忽然想起这个问题，感觉有了新的理解。  

## 重新设计推荐系统
这事得从根本说起。  
推荐系统其实就是一个物品(item)和用户画像(user profile)做匹配的系统。  
假如不考虑计算资源的问题，让我设计一个推荐系统，(假设离线模型已经训练好，只涉及在线推荐部分，)我会这么设计：
### v1版：  
直接遍历内容池里的所有物品，和用户画像计算相似度，取topn的作为推荐物品依次返回。  
这个相似度的计算，随着迭代计算量会很大，能十分精准的对用户的兴趣进行建模，对物品排序。这个模块映射到现有的推荐系统里，其实就是精排模块——特征最多、计算最复杂的模块。  

### v2版：  
显然，这个系统计算量太大了。像抖音快手这类app，其内容池里有上亿item，对每个用户逐个计算，是不可能的。所以这个系统要优化。  
现在出第二版，你需要设计一个模块，放到v1版的所谓“精排”模块之前。作用就是用较低的计算量，筛选掉精排中可能排序靠后的item，以降低精排的计算量。你该怎么做？  
如果是我，我大概会这样做。由于这个新模块的目标是筛选掉精排模块靠后的item，所以它的排序结果应该尽可能和精排一致。所以，假设精排模型有10000个特征，我会尝试评估特征的重要度。筛选出top1000重要的特征。通过这些特征预估，排序出的结果和精排排序出的结果，topn重合度接近100%，但计算量降至1/10。  
所以，现在有了粗排模块，这个模块用精排top1000的特征对所有内容池中的物品和用户画像进行相似度计算，只保留topn的给到精排。  
通过这版迭代，整个系统的计算量，从原来的：  
user_num * item_num * 10000feature,  
降低为user_num * item_num * 1000feature + user_num * n * 10000feature。  
差值为:  
user_num * item_num * 1000feature + user_num * n * 10000feature - user_num * item_num * 10000feature  
假设内容池有1亿物品，用户4亿，最终推荐给用户120个，代入得：  
4*10^9 * 1000feature(10^9+(120-10^9)10feature)=-3.6 * 10^22feature
计算量大大降低。  

### v3版
依次类推，可以继续在粗排前面加模块，用更低的计算量，对可能在下一个模块被淘汰的物品进行筛选。于是，有了召回。  

### 级联系统  
至此，一个漏斗型的在线推荐系统诞生了。  
需要注意的是，上面在设计粗排时，用的是精排的top1000重要度特征来构建的，因为同时要考虑到计算量的降低，以及topn排序结果和精排的一致性。所谓策略的一致性，由此而来。"策略"可以理解为，筛选出哪些物品给到下一模块的策略。这是级联系统要保证的特性。  

## 两种一致性

### 离在线一致性
先说说我熟悉的，离在线一致性。  

### 在线模块间一致性
#### 样本一致性


#### 策略一致性
